{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataPreprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Movielen-100k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle #store model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import itertools\n",
    "import random\n",
    "def get_rate():\n",
    "    ratings = []\n",
    "    with open('./ml-100k/u.data')as f:\n",
    "        for line in itertools.islice(f, 0, None):\n",
    "            user,movie,rate = line.strip('\\r\\n').split('\\t')[:3]\n",
    "            ratings.append([int(user),int(movie),int(rate)])\n",
    "    return ratings\n",
    "res = get_rate()\n",
    "print(len(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(ratings,test_size = 0.2):\n",
    "\n",
    "    train, test = collections.defaultdict(dict), collections.defaultdict(dict)\n",
    "    \n",
    "    trainset_len = 0\n",
    "    testset_len = 0\n",
    "    \n",
    "\n",
    "    for user,movie,rate in ratings:\n",
    "        if random.random() < test_size:\n",
    "            test[user][movie] = int(rate)\n",
    "            testset_len += 1\n",
    "        else:\n",
    "            train[user][movie] = int(rate)\n",
    "            trainset_len += 1\n",
    "    return train,test\n",
    "trainset,testset = train_test_split(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building movie-user table...\n",
      "Build movie-user table success!\n",
      "Build user co-rated movies matrix ...\n",
      "Build user co-rated movies matrix success!\n",
      "Calculating user similarity matrix ...\n",
      "Calculate user similarity matrix success!\n",
      "Building movie-user table...\n",
      "Build movie-user table success!\n",
      "Build user co-rated movies matrix ...\n",
      "Build user co-rated movies matrix success!\n",
      "Calculating user similarity matrix ...\n",
      "Calculate user similarity matrix success!\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "def cal_user_sim(trainset,iif = False):\n",
    "    print('Building movie-user table...')\n",
    "    movie_user = collections.defaultdict(set)\n",
    "    for user,movie in trainset.items():\n",
    "        for m in movie:\n",
    "            movie_user[m].add(user)\n",
    "    print('Build movie-user table success!')\n",
    "    \n",
    "    movie_count = len(movie_user)\n",
    "    \n",
    "    user_sim_matrix = {}\n",
    "    print('Build user co-rated movies matrix ...')\n",
    "    for movie, users in movie_user.items():\n",
    "            for u in users:\n",
    "                for v in users:\n",
    "                    if u == v:\n",
    "                        continue\n",
    "                    user_sim_matrix.setdefault(u, defaultdict(int))\n",
    "                    user_sim_matrix[u].setdefault(v, 0)\n",
    "                    if iif:\n",
    "                        user_sim_matrix[u][v] += 1 / math.log(1 + len(users))\n",
    "                    else:    \n",
    "                        user_sim_matrix[u][v] += 1\n",
    "    print('Build user co-rated movies matrix success!')\n",
    "    \n",
    "    \n",
    "    print('Calculating user similarity matrix ...')\n",
    "    for u, related_users in user_sim_matrix.items():\n",
    "        for v, count in related_users.items():\n",
    "            ##print(u,v)\n",
    "            user_sim_matrix[u][v] = count / math.sqrt(len(trainset[u]) * len(trainset[v]))\n",
    "    print('Calculate user similarity matrix success!')\n",
    "    \n",
    "    return user_sim_matrix,movie_count\n",
    "user_sim_matrix1,movie_count1 = cal_user_sim(trainset)\n",
    "user_sim_matrix2,movie_count2 = cal_user_sim(trainset,iif = True)\n",
    "# print(user_sim_matrix[393])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_popular(trainset):\n",
    "    popularity_list = defaultdict(int)\n",
    "\n",
    "    for user, movies in trainset.items():\n",
    "        for m in movies:\n",
    "            popularity_list[m] += 1\n",
    "\n",
    "    return popularity_list\n",
    "popularity = movie_popular(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Recommended Movies---------\n",
      "\n",
      "['Star Wars (1977)', 'Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1963)', 'Pulp Fiction (1994)', \"Schindler's List (1993)\", 'Fargo (1996)', 'Dead Poets Society (1989)', \"One Flew Over the Cuckoo's Nest (1975)\", 'Seven (Se7en) (1995)', 'GoodFellas (1990)', 'Hudsucker Proxy, The (1994)']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "def recommend(trainset, user_sim_matrix, user, nsimuser = 20, nrecmov = 10):\n",
    "    K = nsimuser \n",
    "    N = nrecmov\n",
    "    rank = {}\n",
    "    watched_movie = trainset[user]\n",
    "    for v, wuv in sorted(user_sim_matrix[user].items(),key = itemgetter(1),reverse = True)[0:K]:\n",
    "        for movie,rating in trainset[v].items():\n",
    "            if movie in watched_movie:\n",
    "                continue\n",
    "            rank.setdefault(movie,0)\n",
    "            rank[movie] += wuv*rating\n",
    "            \n",
    "    return sorted(rank.items(),key = itemgetter(1),reverse=True)[0:N]\n",
    "rec = recommend(trainset, user_sim_matrix1, 1)\n",
    "movie_data = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1')\n",
    "print(\"---------Recommended Movies---------\" + '\\n')\n",
    "print([movie_data.iloc[r[0] - 2][1] for r in rec])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n",
      "precision=0.3131\trecall=0.1470\tcoverage=0.2118\tpopularity=5.4123\n",
      "\n",
      "Evaluation start ...\n",
      "precision=0.3150\trecall=0.1479\tcoverage=0.2203\tpopularity=5.3870\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def evaluate(trainset, testset, movie_count, iif = False, nrecmov = 10):\n",
    "    print(\"Evaluation start ...\")\n",
    "    N = nrecmov\n",
    "    \n",
    "    hit = 0\n",
    "    rec_count = 0\n",
    "    test_count = 0\n",
    "    \n",
    "    all_rec_movies = set()\n",
    "    popular_sum = 0\n",
    "    for i,user in enumerate(trainset):\n",
    "        test_movies = testset.get(user,{})\n",
    "        if not iif:\n",
    "            rec_movies = recommend(trainset, user_sim_matrix1, user)\n",
    "        else:\n",
    "            rec_movies = recommend(trainset, user_sim_matrix2, user)\n",
    "        for movie, w in rec_movies:\n",
    "            if movie in test_movies:\n",
    "                hit += 1\n",
    "            all_rec_movies.add(movie)\n",
    "            popular_sum += math.log(1 + popularity[movie])\n",
    "        rec_count += N\n",
    "        test_count += len(test_movies)\n",
    "    precision = hit / (1.0 * rec_count)\n",
    "    recall = hit / (1.0 * test_count)\n",
    "    coverage = len(all_rec_movies) / (1.0 * movie_count)\n",
    "    popularity_score = popular_sum / (1.0 * rec_count)\n",
    "    print('precision=%.4f\\trecall=%.4f\\tcoverage=%.4f\\tpopularity=%.4f\\n' %\n",
    "          (precision, recall, coverage, popularity_score))\n",
    "evaluate(trainset, testset, movie_count1,)\n",
    "evaluate(trainset, testset, movie_count2, iif = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "import itertools\n",
    "import math\n",
    "\n",
    "# Read data files:\n",
    "train_data = pd.read_csv('ml-100k/ua.base', sep='\\t')\n",
    "test_data = pd.read_csv('ml-100k/ua.test', sep='\\t')\n",
    "\n",
    "# Create matrices with ratings\n",
    "train, test = collections.defaultdict(dict), collections.defaultdict(dict)\n",
    "\n",
    "for row in train_data.itertuples():\n",
    "    train[row[1]][row[2]] = row[3]\n",
    "    \n",
    "for row in test_data.itertuples():\n",
    "    test[row[1]][row[2]] = row[3]\n",
    "#I changed to the same train test set for compare USER and ITEM\n",
    "train,test = train_test_split(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate popularity of each movie in data set\n",
    "def cal_popularity(trainset):\n",
    "    popularity_list = defaultdict(int)\n",
    "\n",
    "    for user, movies in trainset.items():\n",
    "        for m in movies:\n",
    "            popularity_list[m] += 1\n",
    "\n",
    "    return popularity_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate movie similarity matrix\n",
    "def cal_item_sim(trainset, iuf = False):\n",
    "    popularity = cal_popularity(trainset)\n",
    "\n",
    "    sim_matrix = {}\n",
    "    for user, movies in trainset.items():\n",
    "        for m1 in movies:\n",
    "            sim_matrix.setdefault(m1, defaultdict(int))\n",
    "            for m2 in movies:\n",
    "                if m1 == m2:\n",
    "                    continue\n",
    "                if not iuf:\n",
    "                    sim_matrix[m1][m2] += 1\n",
    "                else:# if a person views a lot of movies, items' similarity will be lower.\n",
    "                    sim_matrix[m1][m2] += 1 / math.log(1 + len(movies))\n",
    "    \n",
    "    for m1, similar_movies in sim_matrix.items():\n",
    "        for m2, score in similar_movies.items():\n",
    "            sim_matrix[m1][m2] = score / math.sqrt(popularity[m1] * popularity[m2])\n",
    "\n",
    "    return sim_matrix, popularity\n",
    "\n",
    "item_sim_matrix1, popularity = cal_item_sim(train)\n",
    "item_sim_matrix2, popularity = cal_item_sim(train,iuf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------Recommended Movies---------\n",
      "\n",
      "['Raiders of the Lost Ark (1981)', 'E.T. the Extra-Terrestrial (1982)', 'Back to the Future (1985)', 'Speed (1994)', 'Groundhog Day (1993)', 'Alien (1979)', 'Scream of Stone (Schrei aus Stein) (1991)', 'Batman (1989)', 'Die Hard: With a Vengeance (1995)', 'Star Trek: The Wrath of Khan (1982)']\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "# Recommend n_rec number of movies for specified user\n",
    "def recommend(trainset, movie_sim_mat, user, n_sim = 20, n_rec = 10):\n",
    "    scores = defaultdict(int)\n",
    "    user_movies = trainset[user]\n",
    "    for movie, rating in user_movies.items():\n",
    "        for similar_movie, similarity in sorted(movie_sim_mat[movie].items(),\n",
    "                                                       key=itemgetter(1), reverse=True)[0:n_sim]:\n",
    "            if similar_movie in user_movies:\n",
    "                continue\n",
    "            scores[similar_movie] += similarity * rating\n",
    "    return sorted(scores.items(), key=itemgetter(1), reverse=True)[0:n_rec]\n",
    "\n",
    "rec = recommend(train, item_sim_matrix1, 1)\n",
    "movie_data = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1')\n",
    "print(\"---------Recommended Movies---------\" + '\\n')\n",
    "print([movie_data.iloc[r[0] - 2][1] for r in rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n",
      "precision=0.3002\trecall=0.1415\tcoverage=0.1245\tpopularity=5.5230\n",
      "\n",
      "Evaluation start ...\n",
      "precision=0.3137\trecall=0.1479\tcoverage=0.1172\tpopularity=5.5403\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test algorithm performance\n",
    "def evaluate(trainset, testset, iuf = False, n_rec = 10):\n",
    "    print(\"Evaluation start ...\")\n",
    "    matches = 0\n",
    "    rec_count = 0\n",
    "    test_count = 0\n",
    "    all_rec_movies = set()\n",
    "    popular_sum = 0\n",
    "\n",
    "    for i, user in enumerate(trainset):\n",
    "        test_movies = testset.get(user, {})\n",
    "        if not iuf:\n",
    "            rec_movies = recommend(trainset, item_sim_matrix1, user)  # type:list\n",
    "        else:\n",
    "            rec_movies = recommend(trainset, item_sim_matrix2, user) \n",
    "        for movie, score in rec_movies:\n",
    "            if movie in test_movies:\n",
    "                matches += 1\n",
    "            all_rec_movies.add(movie)\n",
    "            popular_sum += math.log(1 + popularity[movie])\n",
    "        rec_count += n_rec\n",
    "        test_count += len(test_movies)\n",
    "    precision = matches / (1.0 * rec_count)\n",
    "    recall = matches / (1.0 * test_count)\n",
    "    coverage = len(all_rec_movies) / (1.0 * len(popularity))\n",
    "    popularity_score = popular_sum / (1.0 * rec_count)\n",
    "\n",
    "    print('precision=%.4f\\trecall=%.4f\\tcoverage=%.4f\\tpopularity=%.4f\\n' %\n",
    "          (precision, recall, coverage, popularity_score))\n",
    "    \n",
    "evaluate(train, test)\n",
    "evaluate(train,test,iuf=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "def train_test_split(ratings,test_size = 0.2):\n",
    "\n",
    "    train, test = collections.defaultdict(dict), collections.defaultdict(dict)\n",
    "    \n",
    "    trainset_len = 0\n",
    "    testset_len = 0\n",
    "    \n",
    "\n",
    "    for user,movie,rate in ratings:\n",
    "        if random.random() < test_size:\n",
    "            test[user][movie] = int(rate)\n",
    "            testset_len += 1\n",
    "        else:\n",
    "            train[user][movie] = int(rate)\n",
    "            trainset_len += 1\n",
    "    return train,test\n",
    "trainset,testset = train_test_split(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def movie_popular(trainset):\n",
    "    popularity_list = defaultdict(int)\n",
    "    maxnum = 0\n",
    "    for user, movies in trainset.items():\n",
    "        for m in movies:\n",
    "            if m > maxnum:\n",
    "                maxnum = m\n",
    "            popularity_list[m] += 1\n",
    "    return popularity_list,maxnum\n",
    "popularity_list,maxnum = movie_popular(trainset)\n",
    "userlen = len(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def newList(data,movieLen = 1682,userLen = 943):\n",
    "        mateData = np.zeros((userLen, movieLen), dtype=float)\n",
    "        for u, item in data.items():\n",
    "            for n, r in item.items():\n",
    "                mateData[int(u)-1][int(n)-1] = float(int(r))\n",
    "        return mateData\n",
    "mateData = newList(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is step:  0 The loss is:  1.8421470082634357\n",
      "This is step:  1 The loss is:  1.2878987377553603\n",
      "This is step:  2 The loss is:  1.0475120043532082\n",
      "This is step:  3 The loss is:  0.9175784077669128\n",
      "This is step:  4 The loss is:  0.8334610275911499\n",
      "This is step:  5 The loss is:  0.7699182444423589\n",
      "This is step:  6 The loss is:  0.7164167837338128\n",
      "This is step:  7 The loss is:  0.6684649325831546\n",
      "This is step:  8 The loss is:  0.624128058045996\n",
      "This is step:  9 The loss is:  0.5825592586009712\n",
      "This is step:  10 The loss is:  0.5433709130920916\n",
      "This is step:  11 The loss is:  0.5063660086769591\n",
      "This is step:  12 The loss is:  0.4714243343515185\n",
      "This is step:  13 The loss is:  0.4384551633506663\n",
      "This is step:  14 The loss is:  0.40737825402614236\n",
      "This is step:  15 The loss is:  0.37811674006500295\n",
      "This is step:  16 The loss is:  0.35059488375746145\n",
      "This is step:  17 The loss is:  0.32473771734788387\n",
      "This is step:  18 The loss is:  0.300471334256457\n",
      "This is step:  19 The loss is:  0.2777233314424086\n",
      "This is step:  20 The loss is:  0.25642321570705673\n",
      "This is step:  21 The loss is:  0.23650271545197304\n",
      "This is step:  22 The loss is:  0.21789599052907552\n",
      "This is step:  23 The loss is:  0.20053975136610008\n",
      "This is step:  24 The loss is:  0.18437330371866156\n",
      "This is step:  25 The loss is:  0.1693385353275294\n",
      "This is step:  26 The loss is:  0.15537985885917036\n",
      "This is step:  27 The loss is:  0.14244412317542762\n",
      "This is step:  28 The loss is:  0.1304805027549971\n",
      "This is step:  29 The loss is:  0.11944037315611206\n",
      "This is step:  30 The loss is:  0.1092771787999402\n",
      "This is step:  31 The loss is:  0.09994629804395473\n",
      "This is step:  32 The loss is:  0.09140490946150442\n",
      "This is step:  33 The loss is:  0.08361186240240434\n",
      "This is step:  34 The loss is:  0.07652755423710132\n",
      "This is step:  35 The loss is:  0.07011381614667574\n",
      "This is step:  36 The loss is:  0.06433380888076125\n",
      "This is step:  37 The loss is:  0.05915192953908021\n",
      "This is step:  38 The loss is:  0.05453373011782088\n",
      "This is step:  39 The loss is:  0.0504458482822828\n",
      "This is step:  40 The loss is:  0.04685595056843068\n",
      "This is step:  41 The loss is:  0.04373268796837696\n",
      "This is step:  42 The loss is:  0.04104566361184537\n",
      "This is step:  43 The loss is:  0.038765412014103266\n",
      "This is step:  44 The loss is:  0.03686338912061193\n",
      "This is step:  45 The loss is:  0.03531197214270776\n",
      "This is step:  46 The loss is:  0.03408446795263847\n",
      "This is step:  47 The loss is:  0.03315512859835212\n",
      "This is step:  48 The loss is:  0.03249917231840593\n",
      "This is step:  49 The loss is:  0.0320928082960683\n"
     ]
    }
   ],
   "source": [
    "def gradDes(dataMatrix,k,alpha,lam,maxCycles):\n",
    "    m, n = np.shape(dataMatrix)\n",
    "    p = np.mat(np.random.random((m, k)))\n",
    "    q = np.mat(np.random.random((k, n)))\n",
    "    \n",
    "    for step in range(maxCycles):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if dataMatrix[i, j] > 0:\n",
    "                    error = dataMatrix[i, j]\n",
    "                    for r in range(k):\n",
    "                        error = error - p[i, r] * q[r, j]\n",
    "                    for r in range(k):\n",
    "                        p[i, r] = p[i, r] + alpha * (2 * error * q[r, j] - lam * p[i, r])\n",
    "                        q[r, j] = q[r, j] + alpha * (2 * error * p[i, r] - lam * q[r, j])\n",
    "\n",
    "        loss = 0.0\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if dataMatrix[i, j] > 0:\n",
    "                    error = 0.0\n",
    "                    for r in range(k):\n",
    "                        error = error + p[i, r] * q[r, j]\n",
    "                    # calculate loss function\n",
    "                    loss = (dataMatrix[i, j] - error) * (dataMatrix[i, j] - error)\n",
    "                    for r in range(k):\n",
    "                        loss = loss + lam * (p[i, r] * p[i, r] + q[r, j] * q[r, j]) / 2\n",
    "        print('This is step: ',step,'The loss is: ',loss)\n",
    "        if loss < 0.001:\n",
    "            break\n",
    "    return p,q\n",
    "p, q = gradDes(mateData, 5, 0.001, 0.01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mateData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-11911cd77a20>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_rec\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mrec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmateData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmovie_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ml-100k/u.item'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'|'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin-1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"---------Recommended Movies---------\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'mateData' is not defined"
     ]
    }
   ],
   "source": [
    "def predict(dataMatrix, user, p, q, n_rec = 10):\n",
    "    n = np.shape(dataMatrix)[1]\n",
    "    predict = {}\n",
    "    for j in range(n):\n",
    "        if dataMatrix[int(user)-1, j] == 0:\n",
    "            predict[j] = (p[int(user)-1,] * q[:, j])[0, 0]\n",
    "\n",
    "    return sorted(predict.items(), key=lambda d: d[1], reverse=True)[0:n_rec]\n",
    "rec = predict(mateData, 1,p,q)\n",
    "movie_data = pd.read_csv('ml-100k/u.item', sep='|', encoding='latin-1')\n",
    "print(\"---------Recommended Movies---------\" + '\\n')\n",
    "print([movie_data.iloc[r[0] - 2][1] for r in rec])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(mateData, trainset, testset, n_rec = 10):\n",
    "    print(\"Evaluation start ...\")\n",
    "    matches = 0\n",
    "    rec_count = 0\n",
    "    test_count = 0\n",
    "    all_rec_movies = set()\n",
    "    popular_sum = 0\n",
    "\n",
    "    for i, user in enumerate(trainset):\n",
    "        test_movies = testset.get(user, {})\n",
    "        rec_movies = predict(mateData, user, p, q, n_rec = 10) \n",
    "        for movie, score in rec_movies:\n",
    "            if movie in testset:\n",
    "                matches += 1\n",
    "            all_rec_movies.add(movie)\n",
    "            popular_sum += math.log(1 + popularity[movie])\n",
    "        rec_count += n_rec\n",
    "        test_count += len(test_movies)\n",
    "    precision = matches / (1.0 * rec_count)\n",
    "    recall = matches / (1.0 * test_count)\n",
    "    coverage = len(all_rec_movies) / (1.0 * len(popularity))\n",
    "    popularity_score = popular_sum / (1.0 * rec_count)\n",
    "\n",
    "    print('precision=%.4f\\trecall=%.4f\\tcoverage=%.4f\\tpopularity=%.4f\\n' %\n",
    "          (precision, recall, coverage, popularity_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation start ...\n",
      "precision=0.8528\trecall=0.4031\tcoverage=0.0843\tpopularity=3.9963\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate(mateData, trainset, testset, n_rec = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
